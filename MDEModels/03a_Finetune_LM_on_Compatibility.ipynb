{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cebebf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from transformers import BertConfig, BertForMaskedLM, BertPreTrainedModel, BertModel, PreTrainedTokenizerFast, DataCollatorForLanguageModeling, BertPreTrainedModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from packaging import version\n",
    "import datasets\n",
    "import torch.nn as nn\n",
    "from tokenizers import Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from typing import Any, Optional, Tuple, Union\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from utils.NSP_source_code import *\n",
    "from utils.computeMDE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639c59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compatability is tuned on Maestro only\n",
    "dataset_choice = 'Maestro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7859cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = {\"Chopin43\": '_C', \n",
    "               \"ChopinAndHannds\": '_CH',\n",
    "               \"Maestro\": '_M'}\n",
    "Key = dataset_map[dataset_choice]\n",
    "handConfigNumsMap = {\"Chopin43\": 110, \n",
    "               \"ChopinAndHannds\": 136,\n",
    "               \"Maestro\": 12047}\n",
    "\n",
    "\n",
    "MDEDir = './Extracted_Repns/MDE' + Key\n",
    "CompatDir = './Datasets/Compat/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad430b6",
   "metadata": {},
   "source": [
    "Load the hand configuration dictionary from when the MDE dataset was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadf80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MDEDir +'/dict/handConf_dict', 'rb') as handle:\n",
    "    hands = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d7727",
   "metadata": {},
   "source": [
    "### Use the hand configuration dict and the computeMDE functions to convert the compatibility MIDI files to MDE representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd61871",
   "metadata": {},
   "source": [
    "First, iterate through the compatibility directory and accumulate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b74bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "midiFiles = []\n",
    "for root, dirs, files in os.walk(CompatDir):\n",
    "    for file in files:\n",
    "        if \".mid\" in file:\n",
    "            name = root  + '/' + file\n",
    "            midiFiles.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ba7cc",
   "metadata": {},
   "source": [
    "Visualize one of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2416cea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/pretty_midi/pretty_midi.py:101: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./Datasets/Compat/MIDI/p1m55-0.mid'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = calculateQANONForCompat(midiFiles[11], visualize=True)\n",
    "midiFiles[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10b052",
   "metadata": {},
   "source": [
    "### There is currently a bug in the compatibility dataset. Some samples (which should all be a measure long) are instead the entire piece and have hundreds of note onsets. Also, some samples have very strange concurrent notes like: './Datasets/Compat/MIDI/p1m55-0.mid'. As a temporary measure, the following code only saves the samples with 16 or less onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464d4b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "labels = []\n",
    "MDEs = []\n",
    "count = 0\n",
    "maxlen = 0\n",
    "badIDX = 0\n",
    "\n",
    "for idx, file in enumerate(midiFiles):\n",
    "    q = calculateQANONForCompat(midiFiles[idx])\n",
    "    label = midiFiles[idx][-5]\n",
    "    \n",
    "    \n",
    "    MDE = computeMDE_from_QANON(q, hands)\n",
    "    \n",
    "\n",
    "    \n",
    "    x = len(MDE.split(' '))\n",
    "    if x>16:\n",
    "        count+=1\n",
    "    else:\n",
    "        if x>maxlen:\n",
    "            maxlen = x\n",
    "            badIDX = idx\n",
    "        MDEs.append(MDE)\n",
    "        labels.append(label)\n",
    "        \n",
    "        lengths.append(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb16d38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d30acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'File number')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(lengths, reverse=True))\n",
    "plt.title(\"Lengths of QANON files in the Compat dataset\")\n",
    "plt.ylabel(\"QANON length\")\n",
    "plt.xlabel(\"File number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab179be",
   "metadata": {},
   "source": [
    "# Setting up MDE BERT\n",
    "The MDE representation consists of 3 things for every note onset in a piece:\n",
    "1. The pitch of the lowest note (a number 1-12 corresponding to A, A#, ....)\n",
    "2. The octave of the lowest note (a number 0-7 corresponding to which octave on the piano)\n",
    "3. The hand configuration (a number 0-136 that maps to a of hand configurations)\n",
    "\n",
    "To feed this information into BERT with standard huggingface components, I am using an intermediate, proxy tokenizer. At each step, the three elements are concatenated with a separation character. For example, a step with pitch 6, octave 2, and hand configuration 12 becomes 6s2s12. With this intermediate step, the sequence is dimension (1, max_seq_len) instead of (3, max_seq_len), so the default huggingface tokenizers, collators, and trainers can be used.\n",
    "\n",
    "Within the modified components, there are 3 separate embedding layers at the encoder and decoder(we effectively have three separate vocabularies). The first step in the encoder is to convert the MDE representation(ie. 6s2s12) back to a separate pitch, octave, hand representation so that it can be passed throgh three separate embedding layers.The outputs of the embedding layers can then be summed so that input to the attention layers has the normal shape (768). The decoder then has to have three separate linear layers to map the hidden state back to pitch, octave, hand.\n",
    "\n",
    "In order to make these changes in huggingface, we need to construct a custom encoder by modifying the BertEmbedding layer, and a custom decoder by modifying the BertLMPredictionHead. We also need to modify the BertForMaskedLM model itself so that the forward function expects three outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d1a14",
   "metadata": {},
   "source": [
    "# Unmodified huggingface functions\n",
    "\n",
    "Many things are used by the three huggingface components we are modifying(embeddings, prediction head, and maskedLM), but not all of them are importable from transformers. The code for these are imported from NSP_source_code.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8342322",
   "metadata": {},
   "source": [
    "### Custom encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ddd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from octave, pitch, hand configuration, and position.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        #Get the mapping from token to encoded representation\n",
    "        self.decoder = {value:key for key, value in config.decoder.items()}\n",
    "        \n",
    "        #Aggregate special tokens\n",
    "        self.maskToken = config.decoder['[MASK]']\n",
    "        self.unkToken = config.decoder['[UNK]']\n",
    "        self.sepToken = config.decoder['[SEP]']\n",
    "        self.padToken = config.decoder['[PAD]']\n",
    "        self.clsToken = config.decoder['[CLS]']\n",
    "        self.specialTokens = [self.maskToken, self.unkToken, self.sepToken, self.padToken, self.clsToken]\n",
    "        \n",
    "        #Declare embedding layers\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.pitch_embeddings = nn.Embedding(config.numPitches, config.hidden_size)\n",
    "        self.handConfig_embeddings = nn.Embedding(config.numConfigs, config.hidden_size)\n",
    "        self.octave_embeddings = nn.Embedding(config.numOctaves, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
    "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "        if version.parse(torch.__version__) > version.parse(\"1.6.0\"):\n",
    "            self.register_buffer(\n",
    "                \"token_type_ids\",\n",
    "                torch.zeros(self.position_ids.size(), dtype=torch.long),\n",
    "                persistent=False,\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0\n",
    "    ):\n",
    "        #Custom code to use 3 embedding layers\n",
    "        #Convert the tokenized MDE representation ie 9s2s55 to pitch=9 octave=2 hand=55 for all tokens in the batch\n",
    "        octaves = []\n",
    "        pitches = []\n",
    "        handConfs = []\n",
    "        #Iterate through the batch\n",
    "        for x in input_ids:\n",
    "            #For each sequence, make a list to store the octave, pitch, and handConf ids\n",
    "            octave = []\n",
    "            pitch = []\n",
    "            handConf = []\n",
    "            #Iterate through the sequence\n",
    "            for y in x:\n",
    "                #If the token is not a special token, decode into the octave_pitch_handConf representation\n",
    "                if y.item() not in self.specialTokens:\n",
    "                    #Split on s\n",
    "                    try:\n",
    "                        code = [int(x) for x in self.decoder[y.item()].split('s')]\n",
    "                    except:\n",
    "                        code = [x for x in self.decoder[y.item()].split('s')]\n",
    "                        print(code)\n",
    "                    #Add each element to the correct list\n",
    "                    octave.append(code[0])\n",
    "                    pitch.append(code[1])\n",
    "                    handConf.append(code[2])\n",
    "                else:\n",
    "                    #Otherwise, make a representation from the special token. ie: a cls token(1) becomes 1_1_1\n",
    "                    octave.append(y.item())\n",
    "                    pitch.append(y.item())\n",
    "                    handConf.append(y.item())\n",
    "            #Aggregate the samples in the batch\n",
    "            octaves.append(octave)\n",
    "            pitches.append(pitch)\n",
    "            handConfs.append(handConf)\n",
    "            \n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "        \n",
    "        #Convert the lists to tensors and put them on the gpu\n",
    "        octTensor = torch.LongTensor(octaves).to(device)\n",
    "        pitchTensor = torch.LongTensor(pitches).to(device)\n",
    "        handConfTensor = torch.LongTensor(handConfs).to(device)\n",
    "        \n",
    "        #Sum the three embeddings\n",
    "        input_embeds = self.handConfig_embeddings(handConfTensor)\\\n",
    "                       +self.octave_embeddings(octTensor)\\\n",
    "                       +self.pitch_embeddings(pitchTensor)\n",
    "        embeddings = input_embeds\n",
    "\n",
    "        #Standard BertEmbeddings code\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "        \n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand(input_shape)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        embeddings += position_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531c633",
   "metadata": {},
   "source": [
    "### Custom Configuration\n",
    "\n",
    "In order for the encoder and MaskedLM to access the dictionary between MDE representation and tokens, we need to pass that in the model's config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d4a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertConfig(BertConfig):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        #The decoder holds the conversion back to the coded representation for the customEmbeddings layer\n",
    "        self.decoder = kwargs.get('decoder')\n",
    "        self.numOctaves = 9\n",
    "        self.numConfigs = handConfigNumsMap[dataset_choice]\n",
    "        self.numPitches = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5f7a8",
   "metadata": {},
   "source": [
    "#### Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b724a5a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmconati\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "#1dd35d404a289e1e49f18069e4fe0a51d28d52c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "186a8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the tokenizer\n",
    "TOKENIZER_SAVEDIR = Path(MDEDir + '/tokenizer')\n",
    "LM_MODEL_SAVEDIR = Path(MDEDir + '/model/Compat')\n",
    "Path(LM_MODEL_SAVEDIR).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91d546d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x7f152a774210>, <torch.cuda.device at 0x7f152a7746d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Cuda available: ', torch.cuda.is_available())\n",
    "[torch.cuda.device(i) for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2f7b2",
   "metadata": {},
   "source": [
    "Load the tokenizer from the LM pretraining task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c065ebc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='Extracted_Repns/MDE_M/tokenizer', vocab_size=28013, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(TOKENIZER_SAVEDIR)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c578d82a",
   "metadata": {},
   "source": [
    "#### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e548ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters of the training\n",
    "\n",
    "MAX_LEN = 16 #max length of training sequences\n",
    "NUM_EPOCHS = 1 #This model converges very quickly (currently)\n",
    "BATCH_SIZE = 160\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3d63f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28013"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = CustomBertConfig(\n",
    "    #The decoder holds the conversion back to the coded representation for the customEmbeddings layer\n",
    "    decoder = tokenizer.vocab,\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    ")\n",
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd4a39",
   "metadata": {},
   "source": [
    "The model is a standard BertForSequenceClassification model with a replaced embeddings layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3625e6ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./Extracted_Repns/MDE_M/best/model were not used when initializing BertForSequenceClassification: ['cls.predictions.decode_hand.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias_h', 'cls.predictions.decode_pitch.bias', 'bert.embeddings.pitch_embeddings.weight', 'cls.predictions.decode_octave.bias', 'cls.predictions.bias_p', 'cls.predictions.transform.dense.weight', 'bert.embeddings.handConfig_embeddings.weight', 'bert.embeddings.octave_embeddings.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decode_pitch.weight', 'cls.predictions.decode_octave.weight', 'cls.predictions.decode_hand.weight', 'cls.predictions.bias_o']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./Extracted_Repns/MDE_M/best/model and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'bert.embeddings.word_embeddings.weight', 'classifier.weight', 'bert.embeddings.token_type_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias'], unexpected_keys=['cls.predictions.bias_p', 'cls.predictions.bias_o', 'cls.predictions.bias_h', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decode_pitch.weight', 'cls.predictions.decode_pitch.bias', 'cls.predictions.decode_octave.weight', 'cls.predictions.decode_octave.bias', 'cls.predictions.decode_hand.weight', 'cls.predictions.decode_hand.bias'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "mpath = MDEDir + '/best/model' #A model could also be in the /model/checkpoint-#### folder\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    mpath,\n",
    "    config=config\n",
    ")\n",
    "device = model.device\n",
    "\n",
    "temp = CustomBertEmbeddings(config).to(device)\n",
    "#Replace the model's embedding layer\n",
    "model.bert.embeddings = temp\n",
    "\n",
    "\n",
    "mdict = torch.load(mpath + '/pytorch_model.bin')\n",
    "\n",
    "model.load_state_dict(mdict, strict = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990da52c",
   "metadata": {},
   "source": [
    "Take the MDEs extracted from the Compat directory, shuffle them, and convert them into a huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5ec1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(labels, MDEs))\n",
    "random.shuffle(temp)\n",
    "labels, MDEs = zip(*temp)\n",
    "\n",
    "split = int(0.8*len(labels))\n",
    "\n",
    "t_labels = labels[:split]\n",
    "v_labels = labels[split:]\n",
    "\n",
    "t_MDEs = MDEs[:split]\n",
    "v_MDEs = MDEs[split:]\n",
    "\n",
    "t_dataset_dict = {}\n",
    "v_dataset_dict = {}\n",
    "\n",
    "t_dataset_dict['labels'] = [int(x) for x in t_labels]\n",
    "t_dataset_dict['text'] = t_MDEs\n",
    "\n",
    "v_dataset_dict['labels'] = [int(x) for x in v_labels]\n",
    "v_dataset_dict['text'] = v_MDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa9f666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length = MAX_LEN+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd4922",
   "metadata": {},
   "source": [
    " Tokenize the dataset and make sure that samples look as expected:\n",
    " 1. A label 1 or 0 for positive or negative match\n",
    " 3. A sequence of tokens representing MDE audio\n",
    " 4. CLS, SEP, and PAD tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75b56259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.28ba/s]\n",
      "100%|██████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  4.64ba/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "v_dataset = Dataset.from_dict(v_dataset_dict)\n",
    "t_dataset = Dataset.from_dict(t_dataset_dict)\n",
    "\n",
    "tokenized_v_datasets = v_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_t_datasets = t_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dbca389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fee34fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 0,\n",
       " 'text': '3s1s61 3s1s646 3s1s29 5s6s1 5s4s1 5s5s1 5s8s1 5s10s1',\n",
       " 'input_ids': [1,\n",
       "  3058,\n",
       "  22970,\n",
       "  2601,\n",
       "  33,\n",
       "  24,\n",
       "  27,\n",
       "  36,\n",
       "  39,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_v_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8510482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=LM_MODEL_SAVEDIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    save_steps=100,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_total_limit=1,\n",
    "    prediction_loss_only=False,\n",
    "    report_to=\"wandb\",\n",
    "    load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc77d142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=2,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_steps=10,\n",
       "evaluation_strategy=IntervalStrategy.STEPS,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=Extracted_Repns/MDE_M/model/runs/May09_22-18-41_mirlab6,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=loss,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=5000,\n",
       "optim=OptimizerNames.ADAMW_HF,\n",
       "output_dir=Extracted_Repns/MDE_M/model,\n",
       "overwrite_output_dir=True,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=160,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "remove_unused_columns=True,\n",
       "report_to=['wandb'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=Extracted_Repns/MDE_M/model,\n",
       "save_on_each_node=False,\n",
       "save_steps=100,\n",
       "save_strategy=IntervalStrategy.STEPS,\n",
       "save_total_limit=1,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_t_datasets,\n",
    "    eval_dataset=tokenized_v_datasets,\n",
    ")\n",
    "trainer.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec1798",
   "metadata": {},
   "source": [
    "# This model converges very quickly (and starts to diverge). I am a little doubtful of the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1db86091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 4673\n",
      "  Num Epochs = 2500\n",
      "  Instantaneous batch size per device = 160\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 320\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mconati/StyleTransferClean/wandb/run-20220509_221621-1s4761hk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mconati/huggingface/runs/1s4761hk\" target=\"_blank\">Extracted_Repns/MDE_M/model</a></strong> to <a href=\"https://wandb.ai/mconati/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type dict that is 1310824 bytes\n",
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='131' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  131/37500 01:24 < 6:45:58, 1.53 it/s, Epoch 8.67/2500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.685656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.490432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.462813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.451634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.467624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.447303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.603621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.533074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.566314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.629068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.659409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.785853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/74 00:03 < 00:00, 19.57 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to Extracted_Repns/MDE_M/model/checkpoint-100\n",
      "Configuration saved in Extracted_Repns/MDE_M/model/checkpoint-100/config.json\n",
      "Model weights saved in Extracted_Repns/MDE_M/model/checkpoint-100/pytorch_model.bin\n",
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1169\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_658653/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1473\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1602\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1603\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2262\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m         )\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2639\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2640\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2641\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2642\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
