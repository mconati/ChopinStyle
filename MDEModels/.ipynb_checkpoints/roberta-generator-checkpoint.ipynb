{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d999fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaForMaskedLM, RobertaTokenizerFast, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15da417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39b6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_SAVEDIR = Path('/home/macosta/ttmp/primus-tokenizer/')\n",
    "LM_MODEL_SAVEDIR = Path('/home/macosta/ttmp/primus-lm-model/')\n",
    "PRIMUS_TXT_FILES = Path('/home/macosta/ttmp/primus-txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0e85caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForMaskedLM.from_pretrained(str(LM_MODEL_SAVEDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be9c9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file /home/macosta/ttmp/primus-tokenizer/config.json not found\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(TOKENIZER_SAVEDIR, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a3a96507",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"<mask>\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "268493fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ef7ff58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(logits.detach().numpy().flatten())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de2abdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000001110000000000000001110000000000000001110000000000000001110000000000000001110000000000'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(np.argmax(logits[0,0].detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e6d9301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_image(tokens):\n",
    "    img_array = np.zeros((len(tokens[0]), len(tokens)), dtype=np.uint8)\n",
    "    for j, column in enumerate(tokens):\n",
    "        for i, char in enumerate(column):\n",
    "            img_array[i, j] = (1-int(char)) * 255\n",
    "    img = Image.fromarray(img_array)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dd384350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_image(file, seed_length=100, pred_length=500, max_len=128, show=True, show_original=True, temp=3):\n",
    "    with open(file, 'r') as f:\n",
    "        data = f.read()\n",
    "    tokens = data.split()\n",
    "    index = int(np.random.random()*(len(tokens) - seed_length))\n",
    "    seed = tokens[index:index + seed_length]\n",
    "    if show_original:\n",
    "        tokens_to_image(seed).show()\n",
    "    accum_tokens = seed\n",
    "    for _ in range(pred_length):\n",
    "        input_string = f\"{' '.join(accum_tokens[-(max_len - 1):])} <mask>\"\n",
    "        inputs = tokenizer(input_string, return_tensors=\"pt\")\n",
    "        logits = model(**inputs).logits\n",
    "        sorted_token_indices = np.argsort(logits[0,0].detach().numpy())\n",
    "        best_guess_with_temp_index = int(np.random.random() * temp) + 1\n",
    "        token = tokenizer.decode(sorted_token_indices[-best_guess_with_temp_index])\n",
    "        accum_tokens.append(token)\n",
    "    img = tokens_to_image(accum_tokens)\n",
    "    img.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "13ac3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(PRIMUS_TXT_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "77e6d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABfCAAAAAA7ND3mAAAA6UlEQVR4nO2YyQ7DMAhEC+r//7J7SLdUFYMXLJvMXJJDwgMCxo6UW7x0AoMQQgjBkgmMTJL4BVLyVBchhBBCyJYQqkp5JuO9/dVjO+XJRHskcrrEQOTnRgzaqG9iBqSWB36jthG1A62QUQGK/XAIGFDPQ3/07TdMhbpcMSm4X8ZUF+jI9o4v7/ALSkTHsnLy34yFk3E9Peuiaz6K/f5rMgbPYB3CAAZ0BANJ+xl43dMRcSATuscvW8eU2OboADO+RyShO8iPcH2uvqs/NKPPLqY8Z0ZCCInThD7JlC5C1oNQVWLHE0LIlSAPAFQdpd1ENyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x95 at 0x7F043424E950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAABfCAAAAAB316VyAAADfElEQVR4nO2c25aDIAxFE1f//5fTBxGQChKIEUp2Z7XaQhKPyk0YJNAAyb3vf6dvAQAQwKXAkInQ/UWbhJCJGAEIotxweEK3A3DKinTaRsLdtg8hcogAhAQf/oG3QMc7xRFTmuCUA9OvavyETBRtIP26oMz2YegIOTK5NUT0AKmAp4MjiL/L3wo+E0VfuA2W8pTxMYhYCrDKG7pMvo5YAswoVkthdm/z1+rPPT+HWJQtRjLpiWAXVUZYd1cq1YYiUFT6FxLBfaKLbKdGS4Zxrix0ryHZ70gNseoEIPd6CXqmLDQMQxZ8vpDIdn2v0rqOyd41cz1ZSvq8LW5qjhNdP9Kn9d1/9z5ObVjJWzUAwYRi9dJT5S0nVoHbi9bEYmBiMVAUK5QWiG4f324287yvcmXFjY9mI6uIJYKJxcDEYmBiMVhOrJ7u0nJi9WBiBWyk1DDGR3GkNJ5gRPA7AcmluRkpTWyHXyoHZAvjrn7S0tVIKcDUBTyqP2XseCK9R/rag74XRizaryw8fbyFpPvnRkox2cBC2Bc/ueTNx+rdVbgXQ6rMao5V5DZWurw/nKd6EVjcvUwdpqkQ4D7RlVCoNq5SK1SE6GpZ5qPGD+8haIFWI0Jy5WcMhdnKGPtDN3+L4X7z5nroMtBf3GhVMlujt1NjrjdYjYPF3B7D+cbO4Yibzud9FcK0ScR0OcBjyNSGr7VMJdzXXyjtYoVzSxXTMR8gTBPUct8zAbe8oONpCPyiEY5YpRN7d9In7kjH89RfLgcMw9DiWIjYaaPYx3KfSd8wWnuZ5MZjhaBfNHkTXvn3uGPqLIdIrmK/nFMKcBTwC5SPbmi7q5WxBUPdkbyTu8lAaQ1t3tzW5EuUd91zvH/6g+1sPwu47zDByrpJnNhKEwR09JLS9c8qhN5RY1v2oxKtXxJO6U43vJXibuSfMvXgDf2LM4efTuFPTrw0v+lUqaxkvYiLsr8MjERHeq4j7mDmUQcA5UKgW6zhiyxBBMqsddq0s9+GqnSLxfvvFOIsU7kYhgEAw62+3zNwR0pvrTUG9EdzSvX5c7Fkm8x/LtYv9q8KspBoS+zPxZJlObFsvaESCiOl/9N9syuLwQhiTTN+OIJY07CcWNYoVcLEMgxjJhRGStkxyI6UXvizkVIFRhBrgIu7jhHEmgYTi4GJxcDEYmBiMTCxGJhYDL6LiCKLibIlUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=300x95 at 0x7F040D952190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = continue_image(PRIMUS_TXT_FILES / str(files[1]), pred_length=200, temp=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
