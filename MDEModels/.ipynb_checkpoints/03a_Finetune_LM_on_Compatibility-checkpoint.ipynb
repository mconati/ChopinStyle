{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cebebf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from transformers import BertConfig, BertForMaskedLM, BertPreTrainedModel, BertModel, PreTrainedTokenizerFast, DataCollatorForLanguageModeling, BertPreTrainedModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from packaging import version\n",
    "import datasets\n",
    "import torch.nn as nn\n",
    "from tokenizers import Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from typing import Any, Optional, Tuple, Union\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from utils.NSP_source_code import *\n",
    "from utils.computeMDE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd155856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compatability is tuned on Maestro only(so far)\n",
    "dataset_choice = 'Maestro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf63624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = {\"Chopin43\": '_C', \n",
    "               \"ChopinAndHannds\": '_CH',\n",
    "               \"Maestro\": '_M'}\n",
    "Key = dataset_map[dataset_choice]\n",
    "\n",
    "\n",
    "#There is only a compat dataset for Maestro currently\n",
    "MDEDir = './Extracted_Repns/MDE' + Key\n",
    "CompatDir = './Datasets/Compat/MIDI'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238379b5",
   "metadata": {},
   "source": [
    "Load the hand configuration dictionary from when the MDE dataset was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadf80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MDEDir +'/dict/handConf_dict', 'rb') as handle:\n",
    "    hands = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9726237",
   "metadata": {},
   "source": [
    "### Use the hand configuration dict and the computeMDE functions to convert the compatibility MIDI files to MDE representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb94a6e",
   "metadata": {},
   "source": [
    "First, iterate through the compatibility directory and accumulate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b74bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "midiFiles = []\n",
    "for root, dirs, files in os.walk(CompatDir):\n",
    "    for file in files:\n",
    "        if \".mid\" in file:\n",
    "            name = root  + '/' + file\n",
    "            midiFiles.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdadfbc",
   "metadata": {},
   "source": [
    "Visualize one of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2416cea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = calculateQANONForCompat(midiFiles[4], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464d4b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "16\n",
      "32\n",
      "62\n",
      "113\n",
      "123\n",
      "147\n",
      "152\n",
      "166\n",
      "176\n",
      "187\n",
      "194\n",
      "225\n",
      "238\n",
      "324\n",
      "339\n",
      "402\n",
      "424\n",
      "440\n",
      "472\n",
      "490\n",
      "505\n",
      "552\n",
      "567\n",
      "568\n",
      "571\n",
      "583\n",
      "590\n",
      "611\n",
      "633\n",
      "634\n",
      "656\n",
      "659\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_601957/2685835251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidiFiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateQANONForCompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidiFiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidiFiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/StyleTransferClean/utils/computeMDE.py\u001b[0m in \u001b[0;36mcalculateQANONForCompat\u001b[0;34m(mid, visualize)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculateQANONForCompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mnote_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNoteEvents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mbscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_notes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstafflines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateBootlegScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/StyleTransferClean/utils/computeMDE.py\u001b[0m in \u001b[0;36mgetNoteEvents\u001b[0;34m(midifile, quant)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_quant\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoteOnsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks_quant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_quant\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_quant\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_quant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_quant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'secs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "labels = []\n",
    "MDEs = []\n",
    "count = 0\n",
    "maxlen = 0\n",
    "\n",
    "for idx, file in enumerate(midiFiles):\n",
    "    q = calculateQANONForCompat(midiFiles[idx])\n",
    "    label = midiFiles[idx][-5]\n",
    "    \n",
    "    \n",
    "    MDE = computeMDE_from_QANON(q, hands)\n",
    "    \n",
    "\n",
    "    \n",
    "    x = len(MDE.split(' '))\n",
    "    if x>100:\n",
    "        print(idx)\n",
    "        count+=1\n",
    "    else:\n",
    "        if x>maxlen:\n",
    "            maxlen = x\n",
    "        MDEs.append(MDE)\n",
    "        labels.append(label)\n",
    "        \n",
    "    lengths.append(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb16d38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d30acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'File number')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(lengths, reverse=True))\n",
    "plt.title(\"Lengths of QANON files in the Compat dataset\")\n",
    "plt.ylabel(\"QANON length\")\n",
    "plt.xlabel(\"File number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab179be",
   "metadata": {},
   "source": [
    "# Setting up MDE BERT\n",
    "The MDE representation consists of 3 things for every note onset in a piece:\n",
    "1. The pitch of the lowest note (a number 1-12 corresponding to A, A#, ....)\n",
    "2. The octave of the lowest note (a number 0-7 corresponding to which octave on the piano)\n",
    "3. The hand configuration (a number 0-136 that maps to a of hand configurations)\n",
    "\n",
    "To feed this information into BERT with standard huggingface components, I am using an intermediate, proxy tokenizer. At each step, the three elements are concatenated with a separation character. For example, a step with pitch 6, octave 2, and hand configuration 12 becomes 6s2s12. With this intermediate step, the sequence is dimension (1, max_seq_len) instead of (3, max_seq_len), so the default huggingface tokenizers, collators, and trainers can be used.\n",
    "\n",
    "Within the modified components, there are 3 separate embedding layers at the encoder and decoder(we effectively have three separate vocabularies). The first step in the encoder is to convert the MDE representation(ie. 6s2s12) back to a separate pitch, octave, hand representation so that it can be passed throgh three separate embedding layers.The outputs of the embedding layers can then be summed so that input to the attention layers has the normal shape (768). The decoder then has to have three separate linear layers to map the hidden state back to pitch, octave, hand.\n",
    "\n",
    "In order to make these changes in huggingface, we need to construct a custom encoder by modifying the BertEmbedding layer, and a custom decoder by modifying the BertLMPredictionHead. We also need to modify the BertForMaskedLM model itself so that the forward function expects three outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d1a14",
   "metadata": {},
   "source": [
    "# Unmodified huggingface functions\n",
    "\n",
    "Many things are used by the three huggingface components we are modifying(embeddings, prediction head, and maskedLM), but not all of them are importable from transformers. The code for these are imported from NSP_source_code.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971ba06",
   "metadata": {},
   "source": [
    "# Modified huggingface code\n",
    "\n",
    "Here are the three elements that I modified from Huggingface. Modified elements are commented\n",
    "\n",
    "Modified MaskedLM, the forward function is changed to calculate loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10f60215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForPreTraining(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.cls = BertPreTrainingHeads(config)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "        self.decoder = {value:key for key, value in config.decoder.items()}\n",
    "        self.maskToken = config.decoder['[MASK]']\n",
    "        self.unkToken = config.decoder['[UNK]']\n",
    "        self.sepToken = config.decoder['[SEP]']\n",
    "        self.padToken = config.decoder['[PAD]']\n",
    "        self.clsToken = config.decoder['[CLS]']\n",
    "        self.specialTokens = [self.maskToken, self.unkToken, self.sepToken, self.padToken, self.clsToken]\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.cls.predictions.decoder = new_embeddings\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        next_sentence_label: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], BertForPreTrainingOutput]:\n",
    "        r\"\"\"\n",
    "            labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "                Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\n",
    "                config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked),\n",
    "                the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\n",
    "            next_sentence_label (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "                Labels for computing the next sequence prediction (classification) loss. Input should be a sequence\n",
    "                pair (see `input_ids` docstring) Indices should be in `[0, 1]`:\n",
    "                - 0 indicates sequence B is a continuation of sequence A,\n",
    "                - 1 indicates sequence B is a random sequence.\n",
    "            kwargs (`Dict[str, any]`, optional, defaults to *{}*):\n",
    "                Used to hide legacy arguments that have been deprecated.\n",
    "        Returns:\n",
    "        Example:\n",
    "        ```python\n",
    "        >>> from transformers import BertTokenizer, BertForPreTraining\n",
    "        >>> import torch\n",
    "        >>> tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> model = BertForPreTraining.from_pretrained(\"bert-base-uncased\")\n",
    "        >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "        >>> outputs = model(**inputs)\n",
    "        >>> prediction_logits = outputs.prediction_logits\n",
    "        >>> seq_relationship_logits = outputs.seq_relationship_logits\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "        pitch_p, octave_p, hand_p, seq_relationship_score = self.cls(sequence_output, pooled_output)\n",
    "        \n",
    "        masked_lm_loss = None\n",
    "        \n",
    "        #For calculating loss, decode the labels from MDE representation (ex 5s3s31) into three sequences\n",
    "        #of pitch, hand, octave\n",
    "        if labels is not None:\n",
    "            octaves = []\n",
    "            pitches = []\n",
    "            handConfs = []\n",
    "            #Iterate through the batch\n",
    "            for x in labels:\n",
    "                #For each sequence, make a list to store the octave, pitch, and handConf ids\n",
    "                octave = []\n",
    "                pitch = []\n",
    "                handConf = []\n",
    "                #Iterate through the sequence\n",
    "                for y in x:\n",
    "                    #If the token is not a mask token, decode into the octave_pitch_handConf representation\n",
    "                    if y.item() != -100 and y.item() not in self.specialTokens:\n",
    "                        #Split on s\n",
    "                        code = [int(x) for x in self.decoder[y.item()].split('s')]\n",
    "                        #Add each element to the correct list\n",
    "                        octave.append(code[0])\n",
    "                        pitch.append(code[1])\n",
    "                        handConf.append(code[2])\n",
    "                    else:\n",
    "                        #Otherwise, make a representation from the mask token ie, -100, -100, -100\n",
    "                        octave.append(y.item())\n",
    "                        pitch.append(y.item())\n",
    "                        handConf.append(y.item())\n",
    "                #Aggregate the samples in the batch\n",
    "                octaves.append(octave)\n",
    "                pitches.append(pitch)\n",
    "                handConfs.append(handConf)\n",
    "            \n",
    "            \n",
    "            #Loss is still cross entropy\n",
    "            loss_fct = CrossEntropyLoss()  # -100 index = padding token\n",
    "            \n",
    "            device = input_ids.device\n",
    "            #Put the new labels on the gpu\n",
    "            octaves = torch.LongTensor(octaves).to(device)\n",
    "            pitches = torch.LongTensor(pitches).to(device)\n",
    "            handConfs = torch.LongTensor(handConfs).to(device)\n",
    "            \n",
    "            #Calculate a loss for each\n",
    "            octave_loss = loss_fct(octave_p.view(-1, octave_p.shape[2]), octaves.view(-1))\n",
    "            pitch_loss = loss_fct(pitch_p.view(-1, pitch_p.shape[2]), pitches.view(-1))\n",
    "            hand_loss = loss_fct(hand_p.view(-1, hand_p.shape[2]), handConfs.view(-1))\n",
    "            \n",
    "            #The returned loss is the sum of the three losses\n",
    "            masked_lm_loss = octave_loss + pitch_loss + hand_loss\n",
    "\n",
    "        total_loss = masked_lm_loss\n",
    "        if next_sentence_label is not None:\n",
    "            next_sentence_loss = loss_fct(seq_relationship_score.view(-1, 2), next_sentence_label.view(-1))\n",
    "            total_loss = next_sentence_loss + masked_lm_loss\n",
    "        \n",
    "        print(\"total, masked, nsp: \")\n",
    "        print(total_loss, masked_lm_loss, next_sentence_loss)\n",
    "            \n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores, seq_relationship_score) + outputs[2:]\n",
    "            return ((total_loss,) + output) if total_loss is not None else output\n",
    "\n",
    "        return BertForPreTrainingOutput(\n",
    "            loss=total_loss,\n",
    "            prediction_logits=[pitch_p, octave_p, hand_p],\n",
    "            seq_relationship_logits=seq_relationship_score,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8342322",
   "metadata": {},
   "source": [
    "### Custom encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f1ddd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from octave, pitch, hand configuration, and position.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        #Get the mapping from token to encoded representation\n",
    "        self.decoder = {value:key for key, value in config.decoder.items()}\n",
    "        \n",
    "        #Aggregate special tokens\n",
    "        self.maskToken = config.decoder['[MASK]']\n",
    "        self.unkToken = config.decoder['[UNK]']\n",
    "        self.sepToken = config.decoder['[SEP]']\n",
    "        self.padToken = config.decoder['[PAD]']\n",
    "        self.clsToken = config.decoder['[CLS]']\n",
    "        self.specialTokens = [self.maskToken, self.unkToken, self.sepToken, self.padToken, self.clsToken]\n",
    "        \n",
    "        #Declare embedding layers\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.pitch_embeddings = nn.Embedding(config.numPitches, config.hidden_size)\n",
    "        self.handConfig_embeddings = nn.Embedding(config.numConfigs, config.hidden_size)\n",
    "        self.octave_embeddings = nn.Embedding(config.numOctaves, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
    "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "        if version.parse(torch.__version__) > version.parse(\"1.6.0\"):\n",
    "            self.register_buffer(\n",
    "                \"token_type_ids\",\n",
    "                torch.zeros(self.position_ids.size(), dtype=torch.long),\n",
    "                persistent=False,\n",
    "            )\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0\n",
    "    ):\n",
    "        #Custom code to use 3 embedding layers\n",
    "        #Convert the tokenized MDE representation ie 9s2s55 to pitch=9 octave=2 hand=55 for all tokens in the batch\n",
    "        octaves = []\n",
    "        pitches = []\n",
    "        handConfs = []\n",
    "        #Iterate through the batch\n",
    "        for x in input_ids:\n",
    "            #For each sequence, make a list to store the octave, pitch, and handConf ids\n",
    "            octave = []\n",
    "            pitch = []\n",
    "            handConf = []\n",
    "            #Iterate through the sequence\n",
    "            for y in x:\n",
    "                #If the token is not a special token, decode into the octave_pitch_handConf representation\n",
    "                if y.item() not in self.specialTokens:\n",
    "                    #Split on s\n",
    "                    try:\n",
    "                        code = [int(x) for x in self.decoder[y.item()].split('s')]\n",
    "                    except:\n",
    "                        code = [x for x in self.decoder[y.item()].split('s')]\n",
    "                        print(code)\n",
    "                    #Add each element to the correct list\n",
    "                    octave.append(code[0])\n",
    "                    pitch.append(code[1])\n",
    "                    handConf.append(code[2])\n",
    "                else:\n",
    "                    #Otherwise, make a representation from the special token. ie: a cls token(1) becomes 1_1_1\n",
    "                    octave.append(y.item())\n",
    "                    pitch.append(y.item())\n",
    "                    handConf.append(y.item())\n",
    "            #Aggregate the samples in the batch\n",
    "            octaves.append(octave)\n",
    "            pitches.append(pitch)\n",
    "            handConfs.append(handConf)\n",
    "            \n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "        \n",
    "        #Convert the lists to tensors and put them on the gpu\n",
    "        octTensor = torch.LongTensor(octaves).to(device)\n",
    "        pitchTensor = torch.LongTensor(pitches).to(device)\n",
    "        handConfTensor = torch.LongTensor(handConfs).to(device)\n",
    "        \n",
    "        #Sum the three embeddings\n",
    "        input_embeds = self.handConfig_embeddings(handConfTensor)\\\n",
    "                       +self.octave_embeddings(octTensor)\\\n",
    "                       +self.pitch_embeddings(pitchTensor)\n",
    "        embeddings = input_embeds\n",
    "\n",
    "        #Standard BertEmbeddings code\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "        \n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand(input_shape)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        embeddings += position_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531c633",
   "metadata": {},
   "source": [
    "### Custom Configuration\n",
    "\n",
    "In order for the encoder and MaskedLM to access the dictionary between MDE representation and tokens, we need to pass that in the model's config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72855cd",
   "metadata": {},
   "source": [
    "# THIS MUST BE CHANGED FOR DIFFERENT DATASETS. THE numCONFIGS COMES FROM CREATING THE HANDCONIG DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "94d4a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertConfig(BertConfig):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        #The decoder holds the conversion back to the coded representation for the customEmbeddings layer\n",
    "        self.decoder = kwargs.get('decoder')\n",
    "        self.numOctaves = 9\n",
    "        #110 for Chopin43\n",
    "        #720 for Maestro\n",
    "        #136 for ChopinAndHannds\n",
    "        self.numConfigs = 720\n",
    "        self.numPitches = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5f7a8",
   "metadata": {},
   "source": [
    "# (Mostly) standard huggingface code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b724a5a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "#1dd35d404a289e1e49f18069e4fe0a51d28d52c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "186a8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the tokenizer\n",
    "TOKENIZER_SAVEDIR = Path('/home/mconati/ttmp/styletransfer/' + MDEDir + '/tokenizer')\n",
    "LM_MODEL_SAVEDIR = Path('/home/mconati/ttmp/styletransfer/' + MDEDir + '/model')\n",
    "Path(LM_MODEL_SAVEDIR).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "59931978",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMUS_TXT_FILES = Path('/home/mconati/ttmp/styletransfer/' + MDEDir + '/text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d2343163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x7f3820ec5850>, <torch.cuda.device at 0x7f3820ec5890>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.cuda.device(i) for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91d546d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  True\n"
     ]
    }
   ],
   "source": [
    "print('Cuda available: ', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "12795a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "MAX_LEN = 128\n",
    "MASKING_PROPORTION = 0.15\n",
    "TXT_LOCATION = Path('/home/mconati/ttmp/styletransfer/' + MDEDir + '/full')\n",
    "files = [str(TXT_LOCATION / path) for path in os.listdir(TXT_LOCATION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb0eb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def makeVocab(MDEDir, threshold = 5):\n",
    "    tpath = '/home/mconati/ttmp/styletransfer/' + MDEDir + '/full/' + \"MDE.txt\"\n",
    "    my_file = open(tpath, \"r\")\n",
    "\n",
    "    # reading the file\n",
    "    data = my_file.read()\n",
    "\n",
    "    # replacing end of line('/n') with ' ' and\n",
    "    # splitting the text it further when '.' is seen.\n",
    "    data = np.array(data.replace('\\n', '').split(\" \"))[:-1]\n",
    "    print(data)\n",
    "\n",
    "    u,counts = np.unique(data, return_counts=True)\n",
    "    pairs = sorted(zip(counts,u), reverse=True)\n",
    "    counts, u = zip(*pairs)\n",
    "    \n",
    "    plt.plot(sorted(counts, reverse=True))\n",
    "    plt.title(\"Vocab\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Token number\")\n",
    "    \n",
    "    threshold = threshold\n",
    "    for idx, c in enumerate(counts):\n",
    "        if c < threshold:\n",
    "            break\n",
    "    vocab_size = idx\n",
    "\n",
    "    vocab = {}\n",
    "    vocab['[UNK]'] = 0\n",
    "    vocab['[CLS]'] = 1\n",
    "    vocab['[SEP]'] = 2\n",
    "    vocab['[PAD]'] = 3\n",
    "    vocab['[MASK]'] = 4\n",
    "    token_offset = 5\n",
    "    for i,qanon in enumerate(u):\n",
    "        if i > vocab_size:\n",
    "            break\n",
    "        vocab[qanon] = token_offset + i \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "edc29fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizer_utils\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9eeef641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4s5s1' '4s7s1' '4s9s1' ... '1s8s0' '5s3s3' '3s3s0']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = makeVocab(MDEDir, 0)\n",
    "tokenizer = tokenizer_utils.BertTokenizer(vocab)\n",
    "\n",
    "tokenizer_dir = TOKENIZER_SAVEDIR\n",
    "tokenizer.save_pretrained(tokenizer_dir)\n",
    "with open(f'{tokenizer_dir}/vocab.pkl','wb') as f:\n",
    "    pickle.dump(vocab,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8625cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT training code basically copied from the Huggingface Esperanto Tutorial from here on out\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6a3d63f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9645"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = CustomBertConfig(\n",
    "    #The decoder holds the conversion back to the coded representation for the customEmbeddings layer\n",
    "    decoder = tokenizer.vocab,\n",
    "    vocab_size=len(vocab),\n",
    ")\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3625e6ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin found in directory /home/mconati/ttmp/styletransfer/MDEMaestro/best/model but there is a file for Flax weights. Use `from_flax=True` to load this model from those weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3150346/1622300219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m model = BertForSequenceClassification.from_pretrained(\n\u001b[1;32m      6\u001b[0m     \u001b[0mmpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAX_WEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m                     raise EnvironmentError(\n\u001b[0;32m-> 1322\u001b[0;31m                         \u001b[0;34mf\"Error no file named {WEIGHTS_NAME} found in directory {pretrained_model_name_or_path} but \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m                         \u001b[0;34m\"there is a file for Flax weights. Use `from_flax=True` to load this model from those \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0;34m\"weights.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Error no file named pytorch_model.bin found in directory /home/mconati/ttmp/styletransfer/MDEMaestro/best/model but there is a file for Flax weights. Use `from_flax=True` to load this model from those weights."
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "mpath = '/home/mconati/ttmp/styletransfer/' + MDEDir + '/best/model'\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    mpath,\n",
    "    config=config\n",
    ")\n",
    "device = model.device\n",
    "\n",
    "temp = CustomBertEmbeddings(config).to(device)\n",
    "#Replace the model's embedding layer\n",
    "model.bert.embeddings = temp\n",
    "\n",
    "mdict = torch.load(mpath + '/pytorch_model.bin')\n",
    "\n",
    "model.load_state_dict(mdict, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d5ec1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(labels, MDEs))\n",
    "random.shuffle(temp)\n",
    "labels, MDEs = zip(*temp)\n",
    "\n",
    "split = int(0.8*len(labels))\n",
    "\n",
    "t_labels = labels[:split]\n",
    "v_labels = labels[split:]\n",
    "\n",
    "t_MDEs = MDEs[:split]\n",
    "v_MDEs = MDEs[split:]\n",
    "\n",
    "t_dataset_dict = {}\n",
    "v_dataset_dict = {}\n",
    "\n",
    "t_dataset_dict['labels'] = [int(x) for x in t_labels]\n",
    "t_dataset_dict['text'] = t_MDEs\n",
    "\n",
    "v_dataset_dict['labels'] = [int(x) for x in v_labels]\n",
    "v_dataset_dict['text'] = v_MDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fa9f666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "75b56259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:01<00:00,  1.24ba/s]\n",
      "100%|| 6/6 [00:06<00:00,  1.11s/ba]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "v_dataset = Dataset.from_dict(v_dataset_dict)\n",
    "t_dataset = Dataset.from_dict(t_dataset_dict)\n",
    "\n",
    "tokenized_v_datasets = v_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_t_datasets = t_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8510482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=LM_MODEL_SAVEDIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2500,\n",
    "    per_device_train_batch_size=1,\n",
    "    save_steps=100,\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_total_limit=1,\n",
    "    prediction_loss_only=False,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fc77d142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=2,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_steps=100,\n",
       "evaluation_strategy=IntervalStrategy.STEPS,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=/home/mconati/ttmp/styletransfer/MDEMaestro/model/runs/May02_08-34-05_mirlab6,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=100,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=2500,\n",
       "optim=OptimizerNames.ADAMW_HF,\n",
       "output_dir=/home/mconati/ttmp/styletransfer/MDEMaestro/model,\n",
       "overwrite_output_dir=True,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=1,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "remove_unused_columns=True,\n",
       "report_to=['wandb'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=/home/mconati/ttmp/styletransfer/MDEMaestro/model,\n",
       "save_on_each_node=False,\n",
       "save_steps=100,\n",
       "save_strategy=IntervalStrategy.STEPS,\n",
       "save_total_limit=1,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_t_datasets,\n",
    "    eval_dataset=tokenized_v_datasets,\n",
    ")\n",
    "trainer.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c7aab",
   "metadata": {},
   "source": [
    "As a sanity check, look that the custom embeddings change by printing before and after training embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "314ca529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4802,  0.3608,  1.5584,  ..., -1.1212,  0.1355, -1.4675],\n",
       "        [ 0.2910,  1.6323,  1.1040,  ...,  0.9983,  1.1828, -0.9377],\n",
       "        [ 1.7219, -0.5225, -0.4857,  ...,  0.4648, -1.4505, -0.1321],\n",
       "        ...,\n",
       "        [ 0.0667,  0.0339,  0.6519,  ..., -0.0993,  0.0299, -1.3638],\n",
       "        [ 0.0319, -0.6201, -0.4270,  ...,  0.6960,  0.4282, -0.6734],\n",
       "        [ 0.5743, -0.8403, -0.9212,  ..., -1.4081, -0.1988,  0.0476]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beforeTrainingHCEmbedding = model.bert.embeddings.handConfig_embeddings.weight\n",
    "beforeTrainingHCEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92fb7f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num parameters: 88267908\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForPreTraining:\n\tMissing key(s) in state_dict: \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"cls.seq_relationship.weight\", \"cls.seq_relationship.bias\". \n\tsize mismatch for bert.embeddings.handConfig_embeddings.weight: copying a param with shape torch.Size([136, 768]) from checkpoint, the shape in current model is torch.Size([110, 768]).\n\tsize mismatch for cls.predictions.bias_h: copying a param with shape torch.Size([136]) from checkpoint, the shape in current model is torch.Size([110]).\n\tsize mismatch for cls.predictions.decode_hand.weight: copying a param with shape torch.Size([136, 768]) from checkpoint, the shape in current model is torch.Size([110, 768]).\n\tsize mismatch for cls.predictions.decode_hand.bias: copying a param with shape torch.Size([136]) from checkpoint, the shape in current model is torch.Size([110]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3124838/2694404807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1483\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForPreTraining:\n\tMissing key(s) in state_dict: \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"cls.seq_relationship.weight\", \"cls.seq_relationship.bias\". \n\tsize mismatch for bert.embeddings.handConfig_embeddings.weight: copying a param with shape torch.Size([136, 768]) from checkpoint, the shape in current model is torch.Size([110, 768]).\n\tsize mismatch for cls.predictions.bias_h: copying a param with shape torch.Size([136]) from checkpoint, the shape in current model is torch.Size([110]).\n\tsize mismatch for cls.predictions.decode_hand.weight: copying a param with shape torch.Size([136, 768]) from checkpoint, the shape in current model is torch.Size([110, 768]).\n\tsize mismatch for cls.predictions.decode_hand.bias: copying a param with shape torch.Size([136]) from checkpoint, the shape in current model is torch.Size([110])."
     ]
    }
   ],
   "source": [
    "loadModel = True\n",
    "BEST_MODEL_SAVEDIR = Path('/home/mconati/ttmp/styletransfer/' + MDEDir + '/MDE43best/model'\n",
    "\n",
    "if loadModel:\n",
    "    #Load a pretrained BERT model\n",
    "    model = BertForPreTraining(config=config)\n",
    "    print('Num parameters:', model.num_parameters())\n",
    "\n",
    "    #Create a custom embedding class\n",
    "    temp = CustomBertEmbeddings(config)\n",
    "    #Replace the model's embedding layer\n",
    "    model.bert.embeddings = temp\n",
    "\n",
    "    mdict = torch.load(BEST_MODEL_SAVEDIR)\n",
    "\n",
    "    model.load_state_dict(mdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e0efaf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1612\n",
      "  Num Epochs = 2500\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2015000\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/data0/mconati/styletransfer/BERT/wandb/run-20220502_034018-3btwile6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mconati/huggingface/runs/3btwile6\" target=\"_blank\">/home/mconati/ttmp/styletransfer/MDE43/model</a></strong> to <a href=\"https://wandb.ai/mconati/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "tensor(12.5669, device='cuda:1', grad_fn=<AddBackward0>) tensor(11.6957, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8712, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.4742, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='109' max='2015000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    109/2015000 00:43 < 229:58:08, 2.43 it/s, Epoch 0.13/2500]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.886200</td>\n",
       "      <td>6.782742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "tensor(11.2651, device='cuda:1', grad_fn=<AddBackward0>) total, masked, nsp: \n",
      "tensor(10.8062, device='cuda:1', grad_fn=<AddBackward0>) tensor(10.1345, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4589, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(9.1455, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.9064, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9064, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.1199, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1199, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(3.9525, device='cuda:1', grad_fn=<AddBackward0>) tensor(15.9427, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(11.6873, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.9525, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(11.4636, device='cuda:1', grad_fn=<AddBackward0>) tensor(11.4512, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.0125, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(15.5687, device='cuda:1', grad_fn=<AddBackward0>) tensor(11.0685, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.5002, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(14.7108, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.2330, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.4778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(9.3502, device='cuda:1', grad_fn=<AddBackward0>) tensor(14.1293, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.3344, device='cuda:1', grad_fn=<AddBackward0>) tensor(10.0104, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0158, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.4306, device='cuda:1', grad_fn=<AddBackward0>)tensor(12.3998, device='cuda:0', grad_fn=<AddBackward0>)  tensor(8.7408, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.4047, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.6590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0260, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(10.5503, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.2535, device='cuda:1', grad_fn=<AddBackward0>) tensor(10.4941, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.1867, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0668, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.0768, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(10.6865, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.0768, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2342, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.4523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(13.8819, device='cuda:1', grad_fn=<AddBackward0>) tensor(12.1139, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.7680, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(5.4066, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.7068, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.6998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(11.4215, device='cuda:1', grad_fn=<AddBackward0>) tensor(6.4464, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.3578, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.4336, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0637, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.2151, device='cuda:1', grad_fn=<AddBackward0>) tensor(11.1871, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.3853, device='cuda:0', grad_fn=<AddBackward0>)tensor(6.3673, device='cuda:1', grad_fn=<AddBackward0>)  tensor(0.8018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8479, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(10.9347, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.0187, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(9.8944, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0402, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(12.0007, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.7057, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.8546, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.3544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1461, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.3088, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.3495, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3088, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.5864, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.6071, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.1174, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.1243, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4828, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.8926, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) total, masked, nsp: \n",
      "tensor(0.8926, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5822, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.0581, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(11.3064, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.7456, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.1436, device='cuda:1', grad_fn=<AddBackward0>)tensor(0.5607, device='cuda:0', grad_fn=<NllLossBackward0>) \n",
      "tensor(5.2440, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8997, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(11.9398, device='cuda:0', grad_fn=<AddBackward0>) tensor(12.5077, device='cuda:1', grad_fn=<AddBackward0>) tensor(11.2231, device='cuda:0', grad_fn=<AddBackward0>) tensor(11.7985, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.7167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7092, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.5679, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.8465, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.0372, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7783, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.7896, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(3.3012, device='cuda:1', grad_fn=<AddBackward0>) tensor(13.7463, device='cuda:0', grad_fn=<AddBackward0>) tensor(2.7761, device='cuda:1', grad_fn=<AddBackward0>) tensor(12.8391, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5252, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.8599, device='cuda:1', grad_fn=<AddBackward0>) tensor(8.7976, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(8.2416, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8599, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(14.7120, device='cuda:1', grad_fn=<AddBackward0>) tensor(8.8244, device='cuda:0', grad_fn=<AddBackward0>) tensor(14.2341, device='cuda:1', grad_fn=<AddBackward0>) tensor(7.8594, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4779, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.2282, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9094, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(4.7145, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9094, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.5331, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(12.5380, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5331, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(12.0217, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.9507, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8528, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8528, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1078, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.9897, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.6558, device='cuda:1', grad_fn=<AddBackward0>) tensor(7.1200, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.1013, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5545, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(9.0536, device='cuda:1', grad_fn=<AddBackward0>) tensor(10.9045, device='cuda:0', grad_fn=<AddBackward0>) tensor(8.4268, device='cuda:1', grad_fn=<AddBackward0>) tensor(10.1409, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6268, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.1721, device='cuda:1', grad_fn=<AddBackward0>) tensor(6.3146, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.5144, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.6561, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6577, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(11.5923, device='cuda:1', grad_fn=<AddBackward0>) tensor(10.9872, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.6051, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(6.4718, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.7092, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.7850, device='cuda:1', grad_fn=<AddBackward0>) tensor(6.1544, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(5.3951, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7850, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.9097, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.0679, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.1909, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.3432, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.7188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7247, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(5.1881, device='cuda:0', grad_fn=<AddBackward0>) total, masked, nsp: \n",
      "tensor(4.4911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6659, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.6970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.6659, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(5.9566, device='cuda:0', grad_fn=<AddBackward0>) total, masked, nsp: \n",
      "tensor(5.3986, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.8319, device='cuda:1', grad_fn=<AddBackward0>)tensor(0.5581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      " tensor(3.9777, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8541, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.4582, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.9691, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9691, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(10.0909, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.0125, device='cuda:1', grad_fn=<AddBackward0>) tensor(9.5490, device='cuda:0', grad_fn=<AddBackward0>) tensor(8.1513, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8612, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(10.3452, device='cuda:1', grad_fn=<AddBackward0>) tensor(9.7987, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5465, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(4.9283, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.3867, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.3136, device='cuda:1', grad_fn=<AddBackward0>) tensor(8.8676, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.4506, device='cuda:1', grad_fn=<AddBackward0>) tensor(8.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8630, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.8108, device='cuda:1', grad_fn=<AddBackward0>)tensor(5.2471, device='cuda:0', grad_fn=<AddBackward0>)  tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(4.4227, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8108, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.7017, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7066, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(6.9854, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7066, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(5.0603, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.3058, device='cuda:1', grad_fn=<AddBackward0>) total, masked, nsp: \n",
      "tensor(0.7545, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3400, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.5760, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.6156, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.6156, device='cuda:1', grad_fn=<NllLossBackward0>)total, masked, nsp: \n",
      "\n",
      "tensor(0.6536, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.5754, device='cuda:0', grad_fn=<AddBackward0>) tensor(7.9783, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(7.1670, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8113, device='cuda:1', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(11.9717, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0175, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(11.5193, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.0175, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.1051, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.4678, device='cuda:1', grad_fn=<AddBackward0>) tensor(6.6490, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.0106, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4572, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.1538, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.9901, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.7957, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.3582, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7920, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.0622, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.6706, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.6917, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.3072, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.3706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3634, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.4271, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.7687, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.1238, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.4733, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3033, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.6848, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.4065, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.1981, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.9301, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.4867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4764, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.2193, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.2193, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.2052, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.2052, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(1.7028, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(1.7028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.1997, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.6971, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.1997, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(1.5879, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.5843, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(8.9812, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.5879, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6030, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.2788, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.4249, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(4.1377, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.2788, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(5.3156, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.0640, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.2516, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(10.1442, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.8191, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.6718, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.1911, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(4.4980, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.1911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1738, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.4113, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.9948, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(4.9323, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4113, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.8114, device='cuda:1', grad_fn=<AddBackward0>) tensor(13.9060, device='cuda:0', grad_fn=<AddBackward0>) tensor(13.0275, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9399, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8715, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.1810, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.0046, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.5532, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.2454, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6277, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.4622, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.3187, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.6549, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.5016, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8074, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(13.0996, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.4285, device='cuda:0', grad_fn=<AddBackward0>) tensor(12.2849, device='cuda:1', grad_fn=<AddBackward0>) tensor(2.8435, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8147, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.8519, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.8984, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9318, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(4.4999, device='cuda:1', grad_fn=<AddBackward0>) total, masked, nsp: \n",
      "tensor(3.6461, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.7273, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8539, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1799, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(4.6706, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.7693, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9013, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.8915, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.5421, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.6649, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.8709, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.9484, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5937, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7940, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.1900, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.2502, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.5571, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.4923, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6329, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.2275, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.7306, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(5.4849, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.7306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7426, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.7538, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6307, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.7538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6307, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(12.4638, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.2100, device='cuda:0', grad_fn=<AddBackward0>) tensor(11.6994, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.5849, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.7644, device='cuda:1', grad_fn=<NllLossBackward0>)tensor(0.6251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.8029, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.5751, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.0049, device='cuda:0', grad_fn=<AddBackward0>) tensor(8.9978, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.7980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5773, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(12.7849, device='cuda:1', grad_fn=<AddBackward0>) tensor(11.9248, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.8602, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(12.9141, device='cuda:0', grad_fn=<AddBackward0>) tensor(12.3638, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(10.7589, device='cuda:1', grad_fn=<AddBackward0>) tensor(9.3944, device='cuda:0', grad_fn=<AddBackward0>) tensor(9.9517, device='cuda:1', grad_fn=<AddBackward0>) tensor(8.8007, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5937, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8072, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.5676, device='cuda:1', grad_fn=<AddBackward0>) tensor(13.6699, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(13.0920, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5676, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.4635, device='cuda:1', grad_fn=<AddBackward0>) tensor(7.8632, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.6011, device='cuda:1', grad_fn=<AddBackward0>) tensor(7.3181, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8624, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.9257, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.6515, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(4.1407, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9257, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.9130, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.9635, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.9920, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.4722, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4912, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.9497, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.7458, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(4.2516, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4941, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.1535, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.6491, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.6293, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.1305, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5185, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.5055, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(13.9085, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(13.4111, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4974, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.4956, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.7834, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4956, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2760, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9990, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9990, device='cuda:1', grad_fn=<NllLossBackward0>)tensor(0.4685, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.3174, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.5866, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.8079, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(9.6528, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9338, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.2106, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.5847, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.3043, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.0651, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9063, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.5495, device='cuda:1', grad_fn=<AddBackward0>) tensor(7.9041, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(7.3657, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5495, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.1074, device='cuda:0', grad_fn=<AddBackward0>) tensor(7.3116, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.6154, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.3703, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(4.7730, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.2441, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5288, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.5151, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.5151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(3.7109, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(3.2179, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4930, device='cuda:1', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.3030, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.1005, device='cuda:1', grad_fn=<AddBackward0>) tensor(7.2638, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.0666, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0339, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(10.4624, device='cuda:0', grad_fn=<AddBackward0>)tensor(5.1000, device='cuda:1', grad_fn=<AddBackward0>)  tensor(10.0413, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.6670, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4330, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.4858, device='cuda:0', grad_fn=<AddBackward0>) tensor(11.2155, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.0898, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.1111, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.3960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(4.5886, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.4516, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.1370, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(6.6729, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.5697, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.1032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.0493, device='cuda:0', grad_fn=<AddBackward0>) tensor(7.1800, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.9979, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.7554, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.0514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4245, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(10.1745, device='cuda:1', grad_fn=<AddBackward0>) tensor(9.7254, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.4491, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(3.9719, device='cuda:0', grad_fn=<AddBackward0>) tensor(3.5045, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(10.3329, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5140, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(9.8300, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5028, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.6382, device='cuda:0', grad_fn=<AddBackward0>) tensor(11.0391, device='cuda:1', grad_fn=<AddBackward0>) tensor(6.6589, device='cuda:0', grad_fn=<AddBackward0>) tensor(10.0834, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(13.2751, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9532, device='cuda:1', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(12.3503, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9532, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(4.6343, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.6683, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.9660, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(7.9389, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.9600, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.9788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(9.6500, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5241, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(9.1253, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5248, device='cuda:1', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1612\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.3369, device='cuda:1') tensor(8.1826, device='cuda:0') tensor(3.6373, device='cuda:1') tensor(7.4816, device='cuda:0') tensor(0.7010, device='cuda:0')\n",
      "tensor(0.6996, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.3034, device='cuda:1') tensor(5.5877, device='cuda:0') tensor(4.8883, device='cuda:0') tensor(0.6994, device='cuda:0')\n",
      "tensor(5.6033, device='cuda:1') tensor(0.7001, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.5104, device='cuda:1') tensor(10.3791, device='cuda:0') tensor(7.8130, device='cuda:1') tensor(9.6815, device='cuda:0') tensor(0.6974, device='cuda:1')\n",
      "tensor(0.6976, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(7.0684, device='cuda:1') tensor(6.3656, device='cuda:1') tensor(0.7029, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(4.9258, device='cuda:0') tensor(4.2219, device='cuda:0') tensor(0.7039, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.4807, device='cuda:0') tensor(5.7795, device='cuda:0') tensor(0.7011, device='cuda:0')\n",
      "tensor(6.7083, device='cuda:1') tensor(6.0105, device='cuda:1') tensor(0.6979, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.0459, device='cuda:1') tensor(7.1881, device='cuda:0') tensor(5.3450, device='cuda:1') tensor(6.4891, device='cuda:0') tensor(0.7010, device='cuda:1')\n",
      "tensor(0.6990, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(5.6234, device='cuda:1') tensor(4.9290, device='cuda:1') tensor(0.6944, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.9049, device='cuda:0') tensor(6.2041, device='cuda:0') tensor(0.7008, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(6.2497, device='cuda:1') tensor(5.5503, device='cuda:1') tensor(0.6995, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(5.8314, device='cuda:0') tensor(5.1309, device='cuda:0') tensor(0.7006, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.7415, device='cuda:1') tensor(8.3357, device='cuda:0') tensor(7.0436, device='cuda:1') tensor(7.6381, device='cuda:0') tensor(0.6979, device='cuda:1')\n",
      "tensor(0.6976, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.4629, device='cuda:1') tensor(7.7362, device='cuda:0') tensor(6.7604, device='cuda:1') tensor(7.0329, device='cuda:0') tensor(0.7025, device='cuda:1')\n",
      "tensor(0.7033, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.8534, device='cuda:1') tensor(9.1438, device='cuda:0') tensor(6.1517, device='cuda:1') tensor(8.4412, device='cuda:0') tensor(0.7016, device='cuda:1')\n",
      "tensor(0.7027, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.6095, device='cuda:1') tensor(5.7930, device='cuda:0') tensor(4.9135, device='cuda:1') tensor(5.0895, device='cuda:0') tensor(0.7036, device='cuda:0')\n",
      "tensor(0.6959, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.9674, device='cuda:1') tensor(4.9556, device='cuda:0') tensor(4.2713, device='cuda:1') tensor(4.2563, device='cuda:0') tensor(0.6961, device='cuda:1')\n",
      "tensor(0.6993, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.8274, device='cuda:1') tensor(7.9039, device='cuda:0') tensor(7.1245, device='cuda:1') tensor(7.2073, device='cuda:0') tensor(0.7029, device='cuda:1')\n",
      "tensor(0.6966, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.7017, device='cuda:0') tensor(5.6124, device='cuda:1') tensor(5.0012, device='cuda:0') tensor(4.9181, device='cuda:1') tensor(0.7005, device='cuda:0')\n",
      "tensor(0.6943, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.4613, device='cuda:1') tensor(8.7835, device='cuda:0') tensor(5.7633, device='cuda:1') tensor(8.0909, device='cuda:0') tensor(0.6980, device='cuda:1')\n",
      "tensor(0.6926, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(9.3530, device='cuda:1') tensor(6.1158, device='cuda:0') tensor(8.6565, device='cuda:1') tensor(5.4161, device='cuda:0') tensor(0.6966, device='cuda:1')\n",
      "tensor(0.6997, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.6767, device='cuda:0') tensor(6.9445, device='cuda:1') tensor(7.9788, device='cuda:0') tensor(0.6979, device='cuda:0')\n",
      "tensor(6.2411, device='cuda:1') tensor(0.7034, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.1802, device='cuda:1') tensor(6.8667, device='cuda:0') tensor(5.4834, device='cuda:1') tensor(6.1668, device='cuda:0') tensor(0.6968, device='cuda:1')\n",
      "tensor(0.6999, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.6914, device='cuda:1') tensor(6.0833, device='cuda:0') tensor(5.9936, device='cuda:1') tensor(5.3837, device='cuda:0') tensor(0.6978, device='cuda:1')\n",
      "tensor(0.6996, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.2157, device='cuda:0') tensor(7.8796, device='cuda:1') tensor(6.5171, device='cuda:0') tensor(0.6985, device='cuda:0')\n",
      "tensor(7.1826, device='cuda:1') tensor(0.6970, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.6808, device='cuda:1') tensor(5.9830, device='cuda:0') tensor(4.9802, device='cuda:1') tensor(5.2817, device='cuda:0') tensor(0.7005, device='cuda:1')\n",
      "tensor(0.7013, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(5.9306, device='cuda:1') tensor(5.2292, device='cuda:1') tensor(0.7013, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.8993, device='cuda:0') tensor(6.1985, device='cuda:0') tensor(0.7007, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.5700, device='cuda:1') tensor(6.0531, device='cuda:0') tensor(4.8705, device='cuda:1') tensor(5.3530, device='cuda:0') tensor(0.7001, device='cuda:0')\n",
      "tensor(0.6996, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.3183, device='cuda:0') tensor(8.4021, device='cuda:1') tensor(7.6195, device='cuda:0') tensor(7.7037, device='cuda:1') tensor(0.6988, device='cuda:0')\n",
      "tensor(0.6984, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.6173, device='cuda:1') tensor(5.9176, device='cuda:1') total, masked, nsp: \n",
      "tensor(0.6997, device='cuda:1')\n",
      "tensor(8.6859, device='cuda:0') tensor(7.9913, device='cuda:0') tensor(0.6947, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.1920, device='cuda:0') tensor(8.2591, device='cuda:1') tensor(7.4931, device='cuda:0') tensor(0.6989, device='cuda:0')\n",
      "tensor(7.5607, device='cuda:1') tensor(0.6984, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.1988, device='cuda:1') tensor(6.0024, device='cuda:0') tensor(5.5003, device='cuda:1') tensor(5.3065, device='cuda:0') tensor(0.6985, device='cuda:1')\n",
      "tensor(0.6959, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.2953, device='cuda:1') tensor(8.1778, device='cuda:0') tensor(6.5931, device='cuda:1') tensor(7.4815, device='cuda:0') tensor(0.7022, device='cuda:1')\n",
      "tensor(0.6963, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(9.0445, device='cuda:0') tensor(8.3408, device='cuda:0') tensor(0.7037, device='cuda:0')\n",
      "tensor(6.3556, device='cuda:1') tensor(5.6535, device='cuda:1') tensor(0.7021, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.1148, device='cuda:1') tensor(5.4855, device='cuda:0') tensor(7.4124, device='cuda:1') tensor(4.7832, device='cuda:0') tensor(0.7024, device='cuda:1')\n",
      "tensor(0.7023, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.4695, device='cuda:1') tensor(7.0480, device='cuda:0') tensor(6.7685, device='cuda:1') tensor(6.3418, device='cuda:0') tensor(0.7010, device='cuda:1')\n",
      "tensor(0.7061, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.5156, device='cuda:0') tensor(5.3720, device='cuda:1') tensor(3.8155, device='cuda:0') tensor(0.7001, device='cuda:0')\n",
      "tensor(4.6738, device='cuda:1') tensor(0.6982, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.3040, device='cuda:1') tensor(7.3546, device='cuda:0') tensor(6.6050, device='cuda:1') tensor(6.6559, device='cuda:0') tensor(0.6990, device='cuda:1')\n",
      "tensor(0.6987, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(6.0328, device='cuda:1') tensor(5.3337, device='cuda:1') tensor(0.6991, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.6330, device='cuda:0') tensor(6.9335, device='cuda:0') tensor(0.6995, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.8803, device='cuda:1') tensor(6.2686, device='cuda:0') tensor(6.1821, device='cuda:1') tensor(5.5640, device='cuda:0') tensor(0.7046, device='cuda:0')\n",
      "tensor(0.6983, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.4077, device='cuda:1') tensor(7.0025, device='cuda:0') tensor(4.7093, device='cuda:1') tensor(6.3020, device='cuda:0') tensor(0.6984, device='cuda:1')\n",
      "tensor(0.7005, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.3014, device='cuda:1') tensor(8.1992, device='cuda:0') tensor(6.6038, device='cuda:1') tensor(7.4962, device='cuda:0') tensor(0.6976, device='cuda:1')\n",
      "tensor(0.7030, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.3319, device='cuda:0') tensor(6.5373, device='cuda:1') tensor(5.6307, device='cuda:0') tensor(5.8368, device='cuda:1') tensor(0.7013, device='cuda:0')\n",
      "tensor(0.7005, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.3408, device='cuda:1') tensor(6.5764, device='cuda:0') tensor(6.6467, device='cuda:1') tensor(5.8734, device='cuda:0') tensor(0.6941, device='cuda:1')\n",
      "tensor(0.7031, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(4.4078, device='cuda:1') tensor(3.7054, device='cuda:1') total, masked, nsp: \n",
      "tensor(0.7024, device='cuda:1')\n",
      "tensor(6.8784, device='cuda:0') tensor(6.1838, device='cuda:0') tensor(0.6946, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.7266, device='cuda:0') tensor(7.4015, device='cuda:1') tensor(7.0271, device='cuda:0') tensor(6.6996, device='cuda:1') tensor(0.6995, device='cuda:0')\n",
      "tensor(0.7019, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.9286, device='cuda:1') tensor(6.8541, device='cuda:0') tensor(6.2240, device='cuda:1') tensor(6.1508, device='cuda:0') tensor(0.7046, device='cuda:1')\n",
      "tensor(0.7033, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(7.3410, device='cuda:1') tensor(6.6396, device='cuda:1') tensor(0.7014, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.1799, device='cuda:0') tensor(5.4753, device='cuda:0') tensor(0.7047, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.1752, device='cuda:1') tensor(7.4280, device='cuda:0') tensor(4.4771, device='cuda:1') tensor(6.7299, device='cuda:0') tensor(0.6981, device='cuda:0')\n",
      "tensor(0.6981, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.1149, device='cuda:1') tensor(6.2237, device='cuda:0') tensor(6.4172, device='cuda:1') tensor(5.5218, device='cuda:0') tensor(0.6977, device='cuda:1')\n",
      "tensor(0.7019, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(9.0823, device='cuda:1') tensor(8.3825, device='cuda:1') total, masked, nsp: \n",
      "tensor(0.6997, device='cuda:1')\n",
      "tensor(5.9538, device='cuda:0') tensor(5.2529, device='cuda:0') tensor(0.7009, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.3925, device='cuda:1') tensor(5.5002, device='cuda:0') tensor(7.6882, device='cuda:1') tensor(4.8049, device='cuda:0') tensor(0.6952, device='cuda:0')\n",
      "tensor(0.7042, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.4242, device='cuda:1') tensor(8.6021, device='cuda:0') tensor(4.7238, device='cuda:1') tensor(7.8970, device='cuda:0') tensor(0.7004, device='cuda:1')\n",
      "tensor(0.7050, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.5520, device='cuda:1') tensor(5.9589, device='cuda:0') tensor(5.8494, device='cuda:1') tensor(5.2657, device='cuda:0') tensor(0.7025, device='cuda:1')\n",
      "tensor(0.6932, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.2565, device='cuda:0') tensor(6.3775, device='cuda:1') tensor(5.5617, device='cuda:0') tensor(0.6947, device='cuda:0')\n",
      "tensor(5.6801, device='cuda:1') tensor(0.6975, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.2989, device='cuda:1') tensor(5.7118, device='cuda:0') tensor(5.5982, device='cuda:1') tensor(5.0105, device='cuda:0') tensor(0.7007, device='cuda:1')\n",
      "tensor(0.7013, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(8.8080, device='cuda:1') tensor(6.2233, device='cuda:0') tensor(8.1073, device='cuda:1') tensor(5.5240, device='cuda:0') tensor(0.7007, device='cuda:1')\n",
      "tensor(0.6993, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.7441, device='cuda:1') tensor(5.3874, device='cuda:0') tensor(5.0448, device='cuda:1') tensor(4.6913, device='cuda:0') tensor(0.6993, device='cuda:1')\n",
      "tensor(0.6961, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.8419, device='cuda:1') tensor(4.1562, device='cuda:0') tensor(7.1427, device='cuda:1') tensor(3.4583, device='cuda:0') tensor(0.6991, device='cuda:1')\n",
      "tensor(0.6980, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.7727, device='cuda:1') tensor(7.5660, device='cuda:0') tensor(4.0766, device='cuda:1') tensor(6.8605, device='cuda:0') tensor(0.6960, device='cuda:1')\n",
      "tensor(0.7055, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.8572, device='cuda:1') tensor(7.3983, device='cuda:0') tensor(6.6966, device='cuda:0') tensor(0.7017, device='cuda:0')\n",
      "tensor(6.1552, device='cuda:1') tensor(0.7020, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(9.6923, device='cuda:1') tensor(6.2072, device='cuda:0') tensor(8.9943, device='cuda:1') tensor(5.5052, device='cuda:0') tensor(0.6980, device='cuda:1')\n",
      "tensor(0.7020, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(5.9133, device='cuda:1') tensor(5.2140, device='cuda:1') tensor(0.6993, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(8.0071, device='cuda:0') tensor(7.3046, device='cuda:0') tensor(0.7025, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.1707, device='cuda:1') tensor(6.5798, device='cuda:0') tensor(5.8748, device='cuda:0') tensor(0.7050, device='cuda:0')\n",
      "tensor(5.4685, device='cuda:1') tensor(0.7022, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.8823, device='cuda:1') tensor(5.8865, device='cuda:0') tensor(4.1786, device='cuda:1') tensor(5.1833, device='cuda:0') tensor(0.7037, device='cuda:1')\n",
      "tensor(0.7032, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.2737, device='cuda:1') tensor(7.9812, device='cuda:0') tensor(5.5731, device='cuda:1') tensor(7.2794, device='cuda:0') tensor(0.7006, device='cuda:1')\n",
      "tensor(0.7019, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.0118, device='cuda:0') tensor(7.1343, device='cuda:1') tensor(5.3123, device='cuda:0') tensor(0.6995, device='cuda:0')\n",
      "tensor(6.4341, device='cuda:1') tensor(0.7002, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.2169, device='cuda:1') tensor(6.2651, device='cuda:0') tensor(5.5163, device='cuda:1') tensor(5.5705, device='cuda:0') tensor(0.7005, device='cuda:1')\n",
      "tensor(0.6945, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(6.6028, device='cuda:1') tensor(5.9035, device='cuda:1') tensor(0.6993, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.4402, device='cuda:0') tensor(6.7438, device='cuda:0') tensor(0.6964, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.7190, device='cuda:1') tensor(8.8690, device='cuda:0') tensor(8.1709, device='cuda:0') tensor(5.0185, device='cuda:1') tensor(0.6981, device='cuda:0')\n",
      "tensor(0.7006, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.3233, device='cuda:1') tensor(7.0278, device='cuda:0') tensor(4.6260, device='cuda:1') tensor(6.3260, device='cuda:0') tensor(0.6973, device='cuda:1')\n",
      "tensor(0.7018, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(9.0333, device='cuda:1') tensor(6.0500, device='cuda:0') tensor(8.3341, device='cuda:1') tensor(5.3475, device='cuda:0') tensor(0.6992, device='cuda:1')\n",
      "tensor(0.7026, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.6500, device='cuda:0') tensor(6.4447, device='cuda:1') tensor(5.9531, device='cuda:0') tensor(0.6969, device='cuda:0')\n",
      "tensor(5.7380, device='cuda:1') tensor(0.7068, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.7389, device='cuda:1') tensor(7.0431, device='cuda:1') tensor(0.6958, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.9881, device='cuda:0') tensor(6.2878, device='cuda:0') tensor(0.7003, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.1268, device='cuda:1') tensor(7.5056, device='cuda:0') tensor(6.4317, device='cuda:1') tensor(6.8073, device='cuda:0') tensor(0.6952, device='cuda:1')\n",
      "tensor(0.6983, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.8160, device='cuda:1') tensor(6.4628, device='cuda:0') tensor(5.7595, device='cuda:0') tensor(0.7034, device='cuda:0')\n",
      "tensor(6.1163, device='cuda:1') tensor(0.6997, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(8.9747, device='cuda:1') tensor(8.2744, device='cuda:1') tensor(0.7002, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.2632, device='cuda:0') tensor(6.5620, device='cuda:0') tensor(0.7012, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.7587, device='cuda:1') tensor(6.9030, device='cuda:0') tensor(5.0644, device='cuda:1') tensor(6.2029, device='cuda:0') tensor(0.6944, device='cuda:1')\n",
      "tensor(0.7001, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.1856, device='cuda:1') tensor(8.2448, device='cuda:0') tensor(7.5385, device='cuda:0') tensor(0.7062, device='cuda:0')\n",
      "tensor(4.4826, device='cuda:1') tensor(0.7030, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.9961, device='cuda:1') tensor(5.5129, device='cuda:0') tensor(7.2960, device='cuda:1') tensor(4.8107, device='cuda:0') tensor(0.7001, device='cuda:1')\n",
      "tensor(0.7023, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(5.5997, device='cuda:1') tensor(4.8960, device='cuda:1') tensor(0.7037, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.4444, device='cuda:0') tensor(6.7448, device='cuda:0') tensor(0.6996, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.1665, device='cuda:1') tensor(9.3800, device='cuda:0') tensor(6.4633, device='cuda:1') tensor(8.6814, device='cuda:0') tensor(0.7032, device='cuda:1')\n",
      "tensor(0.6985, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.6183, device='cuda:1') tensor(7.3422, device='cuda:0') tensor(5.9156, device='cuda:1') tensor(6.6436, device='cuda:0') tensor(0.7027, device='cuda:1')\n",
      "tensor(0.6986, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(5.9410, device='cuda:1') tensor(5.2411, device='cuda:1') tensor(0.6999, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(5.7562, device='cuda:0') tensor(5.0575, device='cuda:0') tensor(0.6987, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.1495, device='cuda:1') tensor(5.5352, device='cuda:0') tensor(4.4470, device='cuda:1') tensor(4.8316, device='cuda:0') tensor(0.7025, device='cuda:1')\n",
      "tensor(0.7035, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.5116, device='cuda:1') tensor(6.1047, device='cuda:0') tensor(6.8125, device='cuda:1') tensor(5.4093, device='cuda:0') tensor(0.6992, device='cuda:1')\n",
      "tensor(0.6954, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(5.9645, device='cuda:1') tensor(5.2623, device='cuda:1') tensor(0.7021, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.9052, device='cuda:0') tensor(7.2080, device='cuda:0') tensor(0.6972, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.4112, device='cuda:1') tensor(6.2465, device='cuda:0') tensor(4.7115, device='cuda:1') tensor(5.5514, device='cuda:0') tensor(0.6997, device='cuda:1')\n",
      "tensor(0.6951, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.2782, device='cuda:1') tensor(7.0749, device='cuda:0') tensor(5.5816, device='cuda:1') tensor(6.3757, device='cuda:0') tensor(0.6966, device='cuda:1')\n",
      "tensor(0.6993, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(7.3127, device='cuda:1') tensor(6.6099, device='cuda:1') tensor(0.7028, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.5730, device='cuda:0') tensor(5.8719, device='cuda:0') tensor(0.7011, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.7442, device='cuda:1') tensor(6.9699, device='cuda:0') tensor(5.0417, device='cuda:1') tensor(6.2705, device='cuda:0') tensor(0.7026, device='cuda:1')\n",
      "tensor(0.6993, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.7929, device='cuda:1') tensor(5.0378, device='cuda:0') tensor(5.0913, device='cuda:1') tensor(4.3402, device='cuda:0') tensor(0.7015, device='cuda:1')\n",
      "tensor(0.6976, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "tensor(8.7700, device='cuda:1') tensor(8.0705, device='cuda:1') tensor(0.6995, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.2289, device='cuda:0') tensor(6.5254, device='cuda:0') tensor(0.7035, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(5.2742, device='cuda:1') tensor(6.2313, device='cuda:0') tensor(4.5767, device='cuda:1') tensor(5.5302, device='cuda:0') tensor(0.6975, device='cuda:1')\n",
      "tensor(0.7011, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.1875, device='cuda:1') tensor(7.7768, device='cuda:0') tensor(6.4904, device='cuda:1') tensor(7.0757, device='cuda:0') tensor(0.7010, device='cuda:0')\n",
      "tensor(0.6970, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.7528, device='cuda:1') tensor(7.0512, device='cuda:1') tensor(0.7016, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(5.9340, device='cuda:0') tensor(5.2327, device='cuda:0') tensor(0.7013, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.3560, device='cuda:1') tensor(5.6355, device='cuda:0') tensor(6.6552, device='cuda:1') tensor(4.9378, device='cuda:0') tensor(0.7008, device='cuda:1')\n",
      "tensor(0.6977, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.8988, device='cuda:1') tensor(8.7588, device='cuda:0') tensor(6.2008, device='cuda:1') tensor(8.0553, device='cuda:0') tensor(0.7035, device='cuda:0')\n",
      "tensor(0.6980, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.0963, device='cuda:1') tensor(5.3976, device='cuda:1') tensor(0.6986, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(7.8624, device='cuda:0') tensor(7.1664, device='cuda:0') tensor(0.6961, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.8444, device='cuda:1') tensor(5.2852, device='cuda:0') tensor(6.1409, device='cuda:1') tensor(4.5818, device='cuda:0') tensor(0.7036, device='cuda:1')\n",
      "tensor(0.7034, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.7592, device='cuda:1') tensor(6.4926, device='cuda:0') tensor(4.0598, device='cuda:1') tensor(5.7912, device='cuda:0') tensor(0.7013, device='cuda:0')\n",
      "tensor(0.6994, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(8.3231, device='cuda:1') tensor(7.6285, device='cuda:1') tensor(0.6947, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(6.1141, device='cuda:0') tensor(5.4147, device='cuda:0') tensor(0.6994, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(7.6372, device='cuda:1') tensor(6.1273, device='cuda:0') tensor(6.9399, device='cuda:1') tensor(5.4310, device='cuda:0') tensor(0.6973, device='cuda:1')\n",
      "tensor(0.6964, device='cuda:0')\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.8483, device='cuda:1') tensor(6.6706, device='cuda:0') tensor(4.1441, device='cuda:1') tensor(5.9723, device='cuda:0') tensor(0.6983, device='cuda:0')\n",
      "tensor(0.7042, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(8.7275, device='cuda:1') tensor(8.0271, device='cuda:1') tensor(0.7004, device='cuda:1')\n",
      "total, masked, nsp: \n",
      "tensor(8.0023, device='cuda:0') tensor(7.2976, device='cuda:0') tensor(0.7047, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/mconati/ttmp/styletransfer/MDE43/model/checkpoint-100\n",
      "Configuration saved in /home/mconati/ttmp/styletransfer/MDE43/model/checkpoint-100/config.json\n",
      "Model weights saved in /home/mconati/ttmp/styletransfer/MDE43/model/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/mconati/ttmp/styletransfer/MDE43/model/checkpoint-300] due to args.save_total_limit\n",
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.8119, device='cuda:1', grad_fn=<AddBackward0>) tensor(6.3359, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(5.5325, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.8119, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8034, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mconati/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.6633, device='cuda:1', grad_fn=<AddBackward0>) tensor(11.1640, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(10.4332, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6633, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(4.1072, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.5131, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.5941, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(0.6242, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:0', grad_fn=<AddBackward0>) tensor(0.6242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(0.4834, device='cuda:1', grad_fn=<AddBackward0>) tensor(8.6350, device='cuda:0', grad_fn=<AddBackward0>) tensor(0., device='cuda:1', grad_fn=<AddBackward0>) tensor(7.6589, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4834, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(6.7544, device='cuda:1', grad_fn=<AddBackward0>) tensor(5.6288, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.3211, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.5539, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.4333, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: total, masked, nsp: \n",
      "\n",
      "tensor(4.9225, device='cuda:0', grad_fn=<AddBackward0>) tensor(6.3968, device='cuda:1', grad_fn=<AddBackward0>) tensor(4.5493, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.2294, device='cuda:1', grad_fn=<AddBackward0>) tensor(0.3732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1674, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "total, masked, nsp: \n",
      "tensor(4.9392, device='cuda:1', grad_fn=<AddBackward0>) tensor(3.3065, device='cuda:0', grad_fn=<AddBackward0>) tensor(4.6187, device='cuda:1', grad_fn=<AddBackward0>) tensor(2.9755, device='cuda:0', grad_fn=<AddBackward0>) tensor(0.3205, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(11.2490, device='cuda:1', grad_fn=<AddBackward0>) tensor(9.8805, device='cuda:1', grad_fn=<AddBackward0>) tensor(1.3685, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "total, masked, nsp: \n",
      "tensor(6.8386, device='cuda:0', grad_fn=<AddBackward0>) tensor(5.4501, device='cuda:0', grad_fn=<AddBackward0>) tensor(1.3885, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3124838/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ttmp/anaconda3/envs/jukebox/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "afterTrainingHCEmbedding = model.bert.embeddings.handConfig_embeddings.weight\n",
    "afterTrainingHCEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f70a42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_SAVEDIR = Path('/home/mconati/ttmp/styletransfer/' + MDEDir + '/best/model')\n",
    "trainer.save_model(BEST_MODEL_SAVEDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e2e3b0",
   "metadata": {},
   "source": [
    "# Code in progress from here on out. Testing to make sure the LM works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b327053",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadModel = True\n",
    "mpath = '/home/mconati/ttmp/styletransfer/' + MDEDir + '/model/best/model/pytorch_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadModel = True\n",
    "mpath = '/home/mconati/ttmp/styletransfer/' + MDEDir + '/model/best/model/pytorch_model.bin'\n",
    "\n",
    "if loadModel:\n",
    "    #Load a pretrained BERT model\n",
    "    model = BertForPreTraining(config=config)\n",
    "    print('Num parameters:', model.num_parameters())\n",
    "\n",
    "\n",
    "    #Create a custom embedding class\n",
    "    temp = CustomBertEmbeddings(config)\n",
    "    #Replace the model's embedding layer\n",
    "    model.bert.embeddings = temp\n",
    "\n",
    "\n",
    "\n",
    "    mdict = torch.load(mpath)\n",
    "\n",
    "    model.load_state_dict(mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def samp2seq(n, dataset, tokenizer, start = 0, stop = -1, maskProb = 0):\n",
    "    samp = dataset[n][\"input_ids\"][start:stop]\n",
    "\n",
    "    a = np.array(samp)\n",
    "    decoder = {value:key for key, value in tokenizer.vocab.items()}\n",
    "    b = [decoder[x] for x in a]\n",
    "    seq = \"\"\n",
    "    for idx, x in enumerate(b):\n",
    "        rand = random.random()\n",
    "        if rand < maskProb and x!='[CLS]' and x!='[SEP]':\n",
    "            x = \"[MASK]\"\n",
    "        if idx == 0:\n",
    "            seq = seq + str(x)\n",
    "        else:\n",
    "            seq = seq + \" \" + str(x)\n",
    "        if idx == len(b)-1:\n",
    "            seq = seq + \" \" + \"[SEP]\"\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a37d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelPred(seq, model, tokenizer):\n",
    "    device = model.device\n",
    "    tokenized = torch.Tensor(tokenizer(seq)[\"input_ids\"]).to(device)\n",
    "    tokenized = tokenized[1:-1].view(1, -1) #get rid of extra CLS and SEP tokens\n",
    "    preds = model(tokenized)['logits']\n",
    "    pitches = torch.argmax(preds[0], axis=2).detach().cpu().numpy().squeeze()\n",
    "    octaves = torch.argmax(preds[1], axis=2).detach().cpu().numpy().squeeze()\n",
    "    handConfs = torch.argmax(preds[2], axis=2).detach().cpu().numpy().squeeze()\n",
    "    numTokens = len(pitches)\n",
    "    \n",
    "    seq = \"\"\n",
    "    for idx, x in enumerate(octaves):\n",
    "        octave = octaves[idx]\n",
    "        pitch = pitches[idx]\n",
    "        hand = handConfs[idx]\n",
    "        MDE = str(octave)+ \"s\" + str(pitch)+ \"s\" + str(hand)\n",
    "        if idx>0 and idx<numTokens-2:\n",
    "            seq = seq + MDE + \" \"\n",
    "        if idx ==numTokens-2:\n",
    "            seq = seq + MDE\n",
    "    \n",
    "    return seq\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69a5a0",
   "metadata": {},
   "source": [
    "Generate test sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f46c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original = samp2seq(0, test_dataset, tokenizer, 0, 50)\n",
    "masked = samp2seq(0, test_dataset, tokenizer, 0, 50, maskProb=0.15)\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1674bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072918a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = modelPred(original, model, tokenizer)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAcc(original, masked, pred):\n",
    "    pred = '[CLS] ' + pred + ' [SEP]'\n",
    "    original = original.split(' ')\n",
    "    masked = masked.split(' ')\n",
    "    pred = pred.split(' ')\n",
    "    \n",
    "    total = 0\n",
    "    octave = 0\n",
    "    pitch = 0\n",
    "    hand = 0\n",
    "\n",
    "    for x, item in enumerate(masked):\n",
    "        if item == '[MASK]' and original[x] !='[PAD]':\n",
    "            actual = original[x].split('s')\n",
    "            predicted = pred[x].split('s')\n",
    "            total +=1\n",
    "            \n",
    "\n",
    "            try:\n",
    "                if actual[0]==predicted[0]:\n",
    "                    octave +=1\n",
    "                if actual[1]==predicted[1]:\n",
    "                    pitch +=1\n",
    "                if actual[2]==predicted[2]:\n",
    "                    hand +=1\n",
    "            except:\n",
    "                print(predicted)\n",
    "                print(actual)\n",
    "                \n",
    "    if total > 0:\n",
    "        octaveAcc = octave/total\n",
    "        pitchAcc = pitch/total\n",
    "        handAcc = hand/total\n",
    "    else:\n",
    "        #NO MASKING OCCURRED!\n",
    "        return -1, -1, -1\n",
    "                \n",
    "\n",
    "    \n",
    "    return octaveAcc, pitchAcc, handAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f26099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkOverWholeSet(maskProb, train_dataset, tokenizer, model):\n",
    "    o_total = 0\n",
    "    p_total = 0\n",
    "    h_total = 0\n",
    "    total = 0\n",
    "    for sampleNum, x in enumerate(tqdm(range(len(train_dataset)))):\n",
    "        original = samp2seq(sampleNum, train_dataset, tokenizer)\n",
    "        masked = samp2seq(sampleNum, train_dataset, tokenizer, maskProb=maskProb)\n",
    "        pred = modelPred(masked, model, tokenizer)\n",
    "\n",
    "        o, p, h = evaluateAcc(original, masked, pred)\n",
    "        if o == -1:\n",
    "            continue\n",
    "        o_total +=o\n",
    "        p_total +=p\n",
    "        h_total +=h\n",
    "        total +=1\n",
    "    if total != 0:\n",
    "        o_acc = o_total/total\n",
    "        p_acc = p_total/total\n",
    "        h_acc = h_total/total\n",
    "        return o_acc, p_acc, h_acc\n",
    "    return 1,1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a217677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def varyMaskAndPlot(maskProbs, test_dataset, tokenizer, model):\n",
    "    o_accs = []\n",
    "    p_accs = []\n",
    "    h_accs = []\n",
    "    for maskProb in maskProbs:\n",
    "        print(\"CHECKING MASKPROB: \" + str(maskProb))\n",
    "        o_acc, p_acc, h_acc = checkOverWholeSet(maskProb, test_dataset, tokenizer, model)\n",
    "        o_accs.append(o_acc)\n",
    "        p_accs.append(p_acc)\n",
    "        h_accs.append(h_acc)\n",
    "    \n",
    "    plt.plot(maskProbs, o_accs, 'g', label='Octave Accuracy')\n",
    "    plt.plot(maskProbs, p_accs, 'b', label='Pitch Accuracy')\n",
    "    plt.plot(maskProbs, h_accs, 'r', label='Hand Configuration Accuracy')\n",
    "\n",
    "\n",
    "    plt.title('Masking Percentage and Prediction Accuracy on Masked Tokens')\n",
    "\n",
    "    plt.xlabel('Masking Percentage')\n",
    "\n",
    "    plt.ylabel('Prediction Accuracy on Masked Tokens')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd140489",
   "metadata": {},
   "source": [
    "Check the accuracies on one sequence from a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleNum = 11\n",
    "maskProb = 0.1\n",
    "\n",
    "original = samp2seq(sampleNum, train_dataset, tokenizer)\n",
    "masked = samp2seq(sampleNum, train_dataset, tokenizer, maskProb=maskProb)\n",
    "pred = modelPred(masked, model, tokenizer)\n",
    "\n",
    "accuracies = evaluateAcc(original, masked, pred)\n",
    "print(\"Octave Accuracy: {}\".format(accuracies[0]))\n",
    "print(\"Pitch Accuracy: {}\".format(accuracies[1]))\n",
    "print(\"Hand Configuration Accuracy: {}\".format(accuracies[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5e880",
   "metadata": {},
   "source": [
    "Check the average accuracy on all sequences in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea8f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maskProb = 0.1\n",
    "checkOverWholeSet(maskProb, train_dataset, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c1fd9",
   "metadata": {},
   "source": [
    "Check for many different masking probabilities and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskProbs = np.arange(20)/20\n",
    "varyMaskAndPlot(maskProbs, test_dataset, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c07a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
